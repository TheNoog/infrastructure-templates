version: '3.7'

networks:
  local-network:
    driver: bridge
    ipam:
      config:
      - subnet: 172.20.0.0/16


services:

  # ============================================
  # APACHE AIRFLOW
  # ============================================
  redis:
    image: redis:latest
    ports:
      - "6379:6379"
    networks:
      - local-network

  postgres:
    image: postgres:13.0
    env_file:
      - config/common.env
    ports:
      - "5432:5432"
    networks:
      - local-network
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U airflow" ]
      interval: 10s
      timeout: 5s
      retries: 5

  airflow-webserver:
    build:
      context: ./docker/airflow
      dockerfile: Dockerfile
    restart: always
    command: webserver
    depends_on:
      - postgres
    ports:
      - "8080:8080"
    env_file:
      - config/common.env
    networks:
      - local-network
    healthcheck:
      test: [ "CMD-SHELL", "[ -f /airflow/airflow-webserver.pid ]" ]
      interval: 30s
      timeout: 30s
      retries: 3

  airflow-worker-1:
    build:
      context: ./docker/airflow
      dockerfile: Dockerfile
    command: worker
    restart: always
    depends_on:
      - airflow-webserver
    ports:
      - "8081:8080"
    env_file:
      - config/common.env
    environment:
      - QUEUE_NAME=queue_1
    networks:
      - local-network

  airflow-worker-2:
    build:
      context: ./docker/airflow
      dockerfile: Dockerfile
    command: worker
    restart: always
    depends_on:
      - airflow-webserver
    ports:
      - "8082:8080"
    env_file:
      - config/common.env
    environment:
      - QUEUE_NAME=queue_2
    networks:
      - local-network

  airflow-flower:
    build:
      context: ./docker/airflow
      dockerfile: Dockerfile
    command: flower
    restart: always
    depends_on:
      - airflow-worker-1
      - airflow-worker-2
    ports:
      - "5555:5555"
    env_file:
      - config/common.env
    networks:
      - local-network




  # ============================================
  # APACHE TINKERPOP
  # ============================================

  tinkerpop-gremlin-console:
    container_name: tinkerpop-gremlin-console
    image: tinkerpop/gremlin-console:3.4
    networks:
      - local-network
    links:
      - tinkerpop-gremlin-server

  tinkerpop-gremlin-server:
    container_name: tinkerpop-gremlin-server
    image: tinkerpop/gremlin-server:3.4
    ports:
     - "8182:8182"
    networks:
      - local-network



  # ============================================
  # Metabase
  # ============================================
  metabase:
    container_name: metabase
    image: metabase/metabase
    ports:
     - "3000:3000"
    networks:
      - local-network



  # ============================================
  # MySQL
  # ============================================
  mysql:
    container_name: mysql
    image: mysql:8.0
    command: --default-authentication-plugin=mysql_native_password
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: test
      MYSQL_DATABASE: test
      MYSQL_USER: test
      MYSQL_PASSWORD: test
    ports:
      - 3306:3306
    networks:
      - local-network

  mysql-adminer:
    container_name: mysql-adminer
    image: adminer:4.8.0
    restart: always
    environment:
      ADMINER_DEFAULT_SERVER: mysql
    ports:
      - 8100:8080
    links:
      - mysql
    networks:
      - local-network



  # ============================================
  # NEO4J
  # ============================================
  neo4j:
    container_name: neo4j
    image: neo4j:4.1.3
    restart: unless-stopped
    ports:
      - 7473:7473
      - 7474:7474
      - 7687:7687
    environment:
      - NEO4J_AUTH=neo4j/test
      - NEO4J_dbms_memory_pagecache_size=1G
      - NEO4J_dbms.memory.heap.initial_size=1G
      - NEO4J_dbms_memory_heap_max__size=1G
    networks:
      - local-network




  # ============================================
  # MongoDB
  # ============================================
  # connect with Robot 3T
  mongodb:
    container_name: mongodb
    image: mongo:5.0.3
    volumes:
      - ./docker/mongodb/init-mongo.js:/docker-entrypoint-initdb.d/init-mongo.js:ro
    ports:
      - 27017:27017
    networks:
      - local-network



  # ============================================
  # Apache Nifi
  # ============================================
  zookeeper: # the configuration manager
    hostname: zookeeper
    container_name: zookeeper
    build:
      context: ./docker/zookeeper
      dockerfile: Dockerfile
    ports:
      - 2888:2888
      - 2181:2181
      - 3888:3888
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    networks:
      - local-network

  nifi:
    image: apache/nifi:1.12.1
    container_name: nifi
    ports:
      - 8090:8090
    environment:
      - NIFI_WEB_HTTP_PORT=8090
      - NIFI_CLUSTER_IS_NODE=true
      - NIFI_CLUSTER_NODE_PROTOCOL_PORT=8082
      - NIFI_ZK_CONNECT_STRING=zookeeper:2181
      - NIFI_ELECTION_MAX_WAIT=1 min
    networks:
      - local-network




  # ============================================
  # APACHE ATLAS
  # ============================================
  atlas:
    build:
      context: ./docker/atlas
      dockerfile: Dockerfile
    container_name: atlas
    ports:
      - 21000:21000
    environment:
      - ATLAS_PROVISION_EXAMPLES=true
    restart: always
    command: /opt/apache-atlas-2.1.0/bin/atlas_start.py
    networks:
      - local-network






  # ============================================
  # CASSANDRA
  # ============================================
  cassandra:
    image: cassandra:latest
    container_name: cassandra
    ports:
      - "9042:9042"
    environment:
      - "MAX_HEAP_SIZE=256M"
      - "HEAP_NEWSIZE=128M"
    restart: always
    networks:
      - local-network
    healthcheck:
      test: ["CMD", "cqlsh", "-u cassandra", "-p cassandra" ,"-e describe keyspaces"]
      interval: 15s
      timeout: 10s
      retries: 10

  cassandra-load-keyspace:
    container_name: cassandra-load-keyspace
    image: cassandra:latest
    depends_on:
      - cassandra
    networks:
      - local-network
    command: /bin/bash -c "echo loading cassandra keyspace && cqlsh cassandra -f /schema.cql"





  # ============================================
  # COCKROACHDB
  # ============================================
  cockroachdb_node_1:
    container_name: cockroachdb_node_1
    image: cockroachdb/cockroach:latest
    volumes:
       - ./data/node_1:/cockroach/cockroach-data
    command: start --insecure
    ports:
      - "26257:26257"
      - "8050:8080"
    networks:
      local-network:
        aliases:
          - node_1

  cockroachdb_node_2:
    container_name: cockroachdb_node_2
    image: cockroachdb/cockroach:latest
    volumes:
       - ./data/node_2:/cockroach/cockroach-data
    command: start --insecure --join=node_1
    networks:
      local-network:
        aliases:
         - node_2





  # ============================================
  # SPARK
  # ============================================
  spark-master:
    build:
      context: ./docker/spark
      dockerfile: Dockerfile
    container_name: spark-master
    hostname: master
    environment:
      MASTER: spark://localhost:7077
      SPARK_WORKER_PORT: 8881
      SPARK_PUBLIC_DNS: localhost
    expose:
      - 7077
      - 6066
      - 4040
      - 8889
      - 8080
    ports:
      - 4040:4040
      - 6066:6066  # Master rest port
      - 7077:7077
      - 8080:8080  # Master dashboard
      - 8888:8888  # Jupyter Notebook
      - 8889:8889  # Jupyter Notebook
      - 8890:8890
    command: bash -c "/opt/spark/sbin/start-master.sh"
    volumes:
      - ../../code:/code
      - ../../data:/data
    networks:
      - local-network

  spark-worker-1:
    build:
      context: ./docker/spark
      dockerfile: Dockerfile
    container_name: spark-worker-1
    hostname: worker
    environment:
      SPARK_PUBLIC_DNS: localhost
      SPARK_MASTER_PORT: 7077
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8081
      SPARK_WORKER_CORES: 1
      SPARK_WORKER_MEMORY: 1g
    links:
      - spark-master
    expose:
      - 8881
    ports:
      - 8081:8081
    command: bash -c "/opt/spark/sbin/start-worker.sh spark://master:7077"
    volumes:
      - ../../code:/code
      - ../../data:/data
    networks:
      - local-network

  spark-worker-2:
    build:
      context: ./docker/spark
      dockerfile: Dockerfile
    container_name: spark-worker-2
    hostname: worker
    environment:
      SPARK_PUBLIC_DNS: localhost
      SPARK_MASTER_PORT: 7077
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8082
      SPARK_WORKER_CORES: 1
      SPARK_WORKER_MEMORY: 1g
    links:
      - spark-master
    expose:
      - 8881
    ports:
      - 8082:8082
    command: bash -c "/opt/spark/sbin/start-worker.sh spark://master:7077"
    volumes:
      - ../../code:/code
      - ../../data:/data
    networks:
      - local-network

  spark-worker-3:
    build:
      context: ./docker/spark
      dockerfile: Dockerfile
    container_name: spark-worker-3
    hostname: worker
    environment:
      SPARK_PUBLIC_DNS: localhost
      SPARK_MASTER_PORT: 7077
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8083
      SPARK_WORKER_CORES: 1
      SPARK_WORKER_MEMORY: 1g
    links:
      - spark-master
    expose:
      - 8881
    ports:
      - 8083:8083
    command: bash -c "/opt/spark/sbin/start-worker.sh spark://master:7077"
    volumes:
      - ../../code:/code
      - ../../data:/data
    networks:
      - local-network





  # ============================================
  # ELASTICSEARCH
  # ============================================
  es01:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.14.1
    container_name: es01
    environment:
      - node.name=es01
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=es02
      - cluster.initial_master_nodes=es01,es02
      - ES_JAVA_OPTS=-XX:UseAVX=2 -Xms1g -Xmx1g
      - bootstrap.memory_lock=true
    volumes:
      - esdata01:/usr/share/elasticsearch/data
    ports:
      - 9200:9200
    ulimits:
      memlock:
        hard: -1
        soft: -1
    healthcheck:
      interval: 20s
      retries: 10
      test: curl -s http://localhost:9200/_cluster/health | grep -vq '"status":"red"'
    networks:
      - local-network

  es02:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.14.1
    container_name: es02
    environment:
      - node.name=es02
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=es01
      - cluster.initial_master_nodes=es01,es02
      - bootstrap.memory_lock=true
      - ES_JAVA_OPTS=-XX:UseAVX=2 -Xms1g -Xmx1g
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - esdata02:/usr/share/elasticsearch/data
    ports:
      - 9201:9200
    networks:
      - local-network

  kibana:
    image: docker.elastic.co/kibana/kibana:7.14.1
    container_name: kibana
    ports:
      - 5601:5601
    environment:
      ELASTICSEARCH_URL: http://es01:9200
      ELASTICSEARCH_HOSTS: http://es01:9200
    depends_on:
      es01:
        condition: service_healthy
    healthcheck:
      interval: 10s
      retries: 20
      test: curl --write-out 'HTTP %{http_code}' --fail --silent --output /dev/null http://localhost:5601/api/status
    networks:
      - local-network

  logstash:
    image: docker.elastic.co/logstash/logstash:7.14.1
    container_name: logstash
    ports:
      - "5000:5000"
    volumes:
      - ./docker/logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
      - ./docker/logstash/pipeline:/usr/share/logstash/pipeline:ro
    environment:
      LS_JAVA_OPTS: "-Xmx256m -Xms256m"
    networks:
      - local-network
    depends_on:
      - es01

  apm:
    container_name: apm
    image: docker.elastic.co/apm/apm-server:7.14.1
    depends_on:
      es01:
        condition: service_healthy
      kibana:
        condition: service_healthy
    cap_add: ["CHOWN", "DAC_OVERRIDE", "SETGID", "SETUID"]
    cap_drop: ["ALL"]
    ports:
    - 8200:8200
    command: >
       apm-server -e
         -E apm-server.rum.enabled=true
         -E setup.kibana.host=kibana:5601
         -E setup.template.settings.index.number_of_replicas=0
         -E apm-server.kibana.enabled=true
         -E apm-server.kibana.host=kibana:5601
         -E output.elasticsearch.hosts=["es01:9200"]
    healthcheck:
      interval: 10s
      retries: 12
      test: curl --write-out 'HTTP %{http_code}' --fail --silent --output /dev/null http://localhost:8200/
    networks:
      - local-network





  # ============================================
  # WORDPRESS
  # ============================================
  wordpress_db:
    container_name: wordpress_db
    image: mysql:8.0
    ports:
     - "3307:3306"
    volumes:
     - ./wordpress_db_data:/var/lib/mysql
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: yourPassword
      MYSQL_DATABASE: wordpress
      MYSQL_USER: wordpress
      MYSQL_PASSWORD: yourPassword
    networks:
      - local-network

  wordpress:
    container_name: wordpress
    depends_on:
     - wordpress_db
    image: wordpress:latest
    ports:
     - "80:80"
    volumes:
     - ./wordpress_db_l3html:/var/www/html
    restart: always
    environment:
      WORDPRESS_DB_HOST: db:3307
      WORDPRESS_DB_USER: wordpress
      WORDPRESS_DB_PASSWORD: yourPassword
    networks:
      - local-network





  # ============================================
  # KAFKA
  # ============================================
  zookeeper-kafka:
    hostname: zookeeper
    container_name: zookeeper
    image: zookeeper:3.7.0
    ports:
      - 2888:2888
      - 2181:2181
      - 3888:3888
    environment:
      ALLOW_ANONYMOUS_LOGIN: "yes"
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - local-network

  kafka:
    container_name: kafka
    image: wurstmeister/kafka:2.13-2.7.0
    depends_on:
      - zookeeper
    ports:
      - 29092:29092
      - 9092:9092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_HOST_NAME: kafka
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    networks:
      - local-network





  # ============================================
  # APACHE OFBIZ
  # ============================================
  # open source accounting software
  ofbiz:
    container_name: ofbiz
    build:
      context: .
      dockerfile: docker/ofbiz/Dockerfile
    ports:
      - "8443:8443"
    # To log into OFBiz, navigate with your browser to
    # https://localhost:8443/accounting or
    # https://localhost:8443/ecommerce for the ecommerce application or
    # https://localhost:8443/webtools for the WebTools application or
    # https://localhost:8443/catalog for the Catalog Manager application.
    # and login with username "admin" and password "ofbiz"




  # ============================================
  # HADOOP
  # ============================================
  hadoop-datanode:
    image: bde2020/hadoop-datanode:latest
    container_name: hadoop-datanode
    restart: always
    environment:
      CORE_CONF_fs_defaultFS: hdfs://hadoop-namenode:8020
    ports:
      - "8021:8020"
    networks:
      - local-network

  hadoop-namenode:
    image: bde2020/hadoop-namenode:latest
    container_name: hadoop-namenode
    depends_on:
      - hadoop-datanode
    restart: always
    environment:
      CORE_CONF_fs_defaultFS: hdfs://hadoop-namenode:8020
    ports:
      - "8020:8020"
    networks:
      - local-network



 


  # ============================================
  # APACHE SOLR
  # ============================================
  solr:
    container_name: solr
    image: solr:8.10.0
    ports:
      - 8983:8983
    networks:
      - local-network



  # ============================================
  # POSTGRESQL
  # ============================================
  postgresql:
    image: postgres:14.0
    container_name: postgresql
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: test
      POSTGRES_PORT: 5432
      POSTGRES_HOST: postgresql
    ports:
      - "5432:5432"
    networks:
      - local-network



  # ============================================
  # PYSPARK
  # ============================================
  pyspark:
    container_name: pyspark
    image: jupyter/pyspark-notebook:latest
    ports:
      - 8888:8888
    # volumes:
      # - ~/projects/github/local_machine/docker_compose/pyspark_code:/notebooks
    networks:
      - local-network




  # ============================================
  # ANSIBLE
  # ============================================
  ansible:
    container_name: ansible
    build:
      context: ./docker/ansible
      dockerfile: Dockerfile
    # ports:
    #   - 8888:8888
    # volumes:
      # - ~/projects/github/local_machine/docker_compose/pyspark_code:/notebooks
    networks:
      - local-network



  # ============================================
  # CHEF
  # ============================================
  chef-server:
    image: chef/chef-server-ctl:14.13.42
    ports:
      - 443:443
    container_name: chef_server
    command: >
       sleep infinity
    networks:
      - local-network

  chef-workstation:
    image: chef/chefworkstation:22.2.809
    # build:
    #   context: https://raw.githubusercontent.com/chef/chef-workstation/main
    #   dockerfile: Dockerfile
    container_name: chef_workstation
    command: >
       sleep infinity
    networks:
      - local-network

  chef-client:
    image: chef/chef:17.9.59
    # build:
    #   context: https://raw.githubusercontent.com/chef/chef/main
    #   dockerfile: Dockerfile
    container_name: chef_client
    command: >
       sleep infinity
    networks:
      - local-network





volumes:
  # elasticsearch
  esdata01:
    driver: local
  esdata02:
    driver: local
  esdata03:
    driver: local

  # wordpress
  wordpress_db_l3html:
  wordpress_db_data:

  # hadoop
  namenode:
  datanode: